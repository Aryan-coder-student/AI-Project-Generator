{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "api_key = os.environ.get(\"SERPAPI_API_KEY\")\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "import requests\n",
    "serpapi = SerpAPIWrapper(serpapi_api_key=api_key)\n",
    "def fetch_related_info(topic):\n",
    "    query = f\"project ideas for {topic}\"\n",
    "    return serpapi.run(query)\n",
    "def fetch_paperswithcode_data(topic):\n",
    "    url = f\"https://paperswithcode.com/api/v1/search/?q={topic}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        papers = data.get(\"results\", [])\n",
    "        if not papers:\n",
    "            return \"No papers found for the given topic.\"\n",
    "        paper_list = []\n",
    "        for paper_data in papers[:5]:\n",
    "            paper = paper_data.get(\"paper\", {})\n",
    "            title = paper.get(\"title\", \"No Title\")\n",
    "            url = paper.get(\"url_abs\", \"No URL\")\n",
    "            paper_list.append(f\"{title}: {url}\")\n",
    "\n",
    "        return \"\\n\".join(paper_list)\n",
    "    else:\n",
    "        return f\"API error with status code {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.7,\n",
    "    max_retries=2,\n",
    "    api_key=groq_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "idea_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"related_info\"],\n",
    "    template=\"\"\"\n",
    "You are an AI project generator. Based on the topic \"{topic}\" and the following information:\n",
    "{related_info}\n",
    "Generate 5 unique project ideas. Each idea should include:\n",
    "1. A brief description of the project.\n",
    "2. Key steps for implementation, including data collection, model development, and evaluation.\n",
    "3. Deployment strategy (e.g., web app, mobile app, or API).\n",
    "\n",
    "Make sure the projects are practical and explainable to a technical audience.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_chain = idea_prompt | llm\n",
    "def generate_ideas(topic, related_info):\n",
    "    input_data = {\n",
    "        'topic': topic,\n",
    "        'related_info': related_info\n",
    "    }\n",
    "    return idea_chain.invoke(input=input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Computer Vision for healthcare, agriculture, and urban development\"\n",
    "serpapi_data = fetch_related_info(topic)\n",
    "papers_data = fetch_paperswithcode_data(topic)\n",
    "combined_related_info = f\"\"\"\n",
    "1. Hackathon projects should be innovative, quick to build, and impactful.\n",
    "2. Computer Vision can be applied in domains like healthcare, agriculture, and urban development.\n",
    "3. Projects should focus on demonstrating real-world applicability and deployability within hackathon time constraints.\n",
    "4. SerpAPI Results: {serpapi_data}\n",
    "5. Should be software solution only.\n",
    "\"\"\"\n",
    "result = generate_ideas(topic, combined_related_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Project Idea 1: CropMonitor - Automated Crop Disease Detection**\n",
       "\n",
       "**Description:** CropMonitor is a computer vision-based system that uses machine learning to detect crop diseases in real-time, enabling farmers to take prompt action and minimize losses.\n",
       "\n",
       "**Key Steps:**\n",
       "\n",
       "1. **Data Collection:** Collect high-quality images of crops with various diseases using drones or cameras. Label each image with the corresponding disease type.\n",
       "2. **Model Development:** Train a deep learning model (e.g., Convolutional Neural Network (CNN)) using the collected data to classify images into healthy or diseased categories.\n",
       "3. **Model Evaluation:** Evaluate the model's performance using metrics such as accuracy, precision, and recall.\n",
       "4. **Deployment:** Develop a web application that allows farmers to upload images of their crops, and the system returns a diagnosis of the disease (if any) along with recommendations for treatment.\n",
       "\n",
       "**Deployment Strategy:** Web Application (using Flask or Django) with a user-friendly interface for farmers to upload images and receive diagnoses.\n",
       "\n",
       "**Project Idea 2: SmartCity - Urban Infrastructure Inspection**\n",
       "\n",
       "**Description:** SmartCity is an AI-powered system that uses computer vision to inspect urban infrastructure (e.g., roads, bridges, and buildings) for damage and defects, enabling cities to prioritize maintenance and prevent accidents.\n",
       "\n",
       "**Key Steps:**\n",
       "\n",
       "1. **Data Collection:** Collect aerial images of urban infrastructure using drones or satellite imagery.\n",
       "2. **Model Development:** Train a deep learning model (e.g., object detection) to identify damage and defects in the infrastructure.\n",
       "3. **Model Evaluation:** Evaluate the model's performance using metrics such as accuracy and IoU (Intersection over Union).\n",
       "4. **Deployment:** Develop a mobile application that allows city officials to upload aerial images of infrastructure and receive a report of damage and defects.\n",
       "\n",
       "**Deployment Strategy:** Mobile Application (using React Native or Flutter) with a user-friendly interface for city officials to upload images and receive reports.\n",
       "\n",
       "**Project Idea 3: MedEye - Automated Medical Imaging Analysis**\n",
       "\n",
       "**Description:** MedEye is an AI-powered system that uses computer vision to analyze medical images (e.g., X-rays and CT scans) to detect abnormalities and provide preliminary diagnoses.\n",
       "\n",
       "**Key Steps:**\n",
       "\n",
       "1. **Data Collection:** Collect medical images from hospitals and label them with corresponding diagnoses.\n",
       "2. **Model Development:** Train a deep learning model (e.g., CNN) using the collected data to classify images into healthy or diseased categories.\n",
       "3. **Model Evaluation:** Evaluate the model's performance using metrics such as accuracy, precision, and recall.\n",
       "4. **Deployment:** Develop a web application that allows doctors to upload medical images, and the system returns a preliminary diagnosis and recommendations for further testing.\n",
       "\n",
       "**Deployment Strategy:** Web Application (using Flask or Django) with a user-friendly interface for doctors to upload images and receive diagnoses.\n",
       "\n",
       "**Project Idea 4: FarmWatch - Automated Crop Yield Estimation**\n",
       "\n",
       "**Description:** FarmWatch is an AI-powered system that uses computer vision to estimate crop yields based on images of crops and weather data.\n",
       "\n",
       "**Key Steps:**\n",
       "\n",
       "1. **Data Collection:** Collect images of crops from drones or cameras, along with weather data (e.g., temperature, humidity, and precipitation).\n",
       "2. **Model Development:** Train a deep learning model (e.g., regression) using the collected data to estimate crop yields.\n",
       "3. **Model Evaluation:** Evaluate the model's performance using metrics such as mean absolute error (MAE) and mean squared error (MSE).\n",
       "4. **Deployment:** Develop a web application that allows farmers to upload images of their crops and receive an estimated yield.\n",
       "\n",
       "**Deployment Strategy:** Web Application (using Flask or Django) with a user-friendly interface for farmers to upload images and receive estimates.\n",
       "\n",
       "**Project Idea 5: UrbanGarden - Smart Gardening with Computer Vision**\n",
       "\n",
       "**Description:** UrbanGarden is an AI-powered system that uses computer vision to analyze images of plants and provide personalized gardening advice, including watering schedules and fertilization recommendations.\n",
       "\n",
       "**Key Steps:**\n",
       "\n",
       "1. **Data Collection:** Collect images of plants from cameras or smartphones, along with environmental data (e.g., temperature, humidity, and light exposure).\n",
       "2. **Model Development:** Train a deep learning model (e.g., CNN) using the collected data to classify images into plant species and provide personalized gardening advice.\n",
       "3. **Model Evaluation:** Evaluate the model's performance using metrics such as accuracy and F1-score.\n",
       "4. **Deployment:** Develop a mobile application that allows gardeners to upload images of their plants and receive personalized advice.\n",
       "\n",
       "**Deployment Strategy:** Mobile Application (using React Native or Flutter) with a user-friendly interface for gardeners to upload images and receive advice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
